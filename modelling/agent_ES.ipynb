{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c8e4374",
   "metadata": {},
   "source": [
    "# EvolutionStrategy-Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39dcac74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import yfinance as yf\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "779e7e25",
   "metadata": {},
   "source": [
    "# DRL Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f318e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Deep_Evolution_Strategy:\n",
    "\n",
    "    inputs = None\n",
    "\n",
    "    def __init__(\n",
    "        self, weights, reward_function, population_size, sigma, learning_rate\n",
    "    ):\n",
    "        self.weights = weights\n",
    "        self.reward_function = reward_function\n",
    "        self.population_size = population_size\n",
    "        self.sigma = sigma\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "    def _get_weight_from_population(self, weights, population):\n",
    "        weights_population = []\n",
    "        for index, i in enumerate(population):\n",
    "            jittered = self.sigma * i\n",
    "            weights_population.append(weights[index] + jittered)\n",
    "        return weights_population\n",
    "\n",
    "    def get_weights(self):\n",
    "        return self.weights\n",
    "\n",
    "    def train(self, epoch = 100, print_every = 1):\n",
    "        lasttime = time.time()\n",
    "        for i in range(epoch):\n",
    "            population = []\n",
    "            rewards = np.zeros(self.population_size)\n",
    "            for k in range(self.population_size):\n",
    "                x = []\n",
    "                for w in self.weights:\n",
    "                    x.append(np.random.randn(*w.shape))\n",
    "                population.append(x)\n",
    "            for k in range(self.population_size):\n",
    "                weights_population = self._get_weight_from_population(\n",
    "                    self.weights, population[k]\n",
    "                )\n",
    "                rewards[k] = self.reward_function(weights_population)\n",
    "            rewards = (rewards - np.mean(rewards)) / (np.std(rewards) + 1e-7)\n",
    "            for index, w in enumerate(self.weights):\n",
    "                A = np.array([p[index] for p in population])\n",
    "                self.weights[index] = (\n",
    "                    w\n",
    "                    + self.learning_rate\n",
    "                    / (self.population_size * self.sigma)\n",
    "                    * np.dot(A.T, rewards).T\n",
    "                )\n",
    "            if (i + 1) % print_every == 0:\n",
    "                print(\n",
    "                    'iter %d. reward: %f'\n",
    "                    % (i + 1, self.reward_function(self.weights))\n",
    "                )\n",
    "        print('time taken to train:', time.time() - lasttime, 'seconds')\n",
    "\n",
    "\n",
    "class Model:\n",
    "    def __init__(self, input_size, layer_size, output_size):\n",
    "        self.weights = [\n",
    "            np.random.randn(input_size, layer_size),\n",
    "            np.random.randn(layer_size, output_size),\n",
    "            np.random.randn(1, layer_size),\n",
    "        ]\n",
    "\n",
    "    def predict(self, inputs):\n",
    "        feed = np.dot(inputs, self.weights[0]) + self.weights[-1]\n",
    "        decision = np.dot(feed, self.weights[1])\n",
    "        return decision\n",
    "\n",
    "    def get_weights(self):\n",
    "        return self.weights\n",
    "\n",
    "    def set_weights(self, weights):\n",
    "        self.weights = weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e089a3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "\n",
    "    POPULATION_SIZE = 15\n",
    "    SIGMA = 0.1\n",
    "    LEARNING_RATE = 0.03\n",
    "\n",
    "    def __init__(self, model, window_size, trend, skip, initial_money):\n",
    "        self.model = model\n",
    "        self.window_size = window_size\n",
    "        self.half_window = window_size // 2\n",
    "        self.trend = trend\n",
    "        self.skip = skip\n",
    "        self.initial_money = initial_money\n",
    "        self.es = Deep_Evolution_Strategy(\n",
    "            self.model.get_weights(),\n",
    "            self.get_reward,\n",
    "            self.POPULATION_SIZE,\n",
    "            self.SIGMA,\n",
    "            self.LEARNING_RATE,\n",
    "        )\n",
    "\n",
    "    def act(self, sequence):\n",
    "        decision = self.model.predict(np.array(sequence))\n",
    "        return np.argmax(decision[0])\n",
    "    \n",
    "    def get_state(self, t):\n",
    "        window_size = self.window_size + 1\n",
    "        d = t - window_size + 1\n",
    "        block = self.trend[d : t + 1] if d >= 0 else -d * [self.trend[0]] + self.trend[0 : t + 1]\n",
    "        res = []\n",
    "        for i in range(window_size - 1):\n",
    "            res.append(block[i + 1] - block[i])\n",
    "        return np.array([res])\n",
    "\n",
    "    def get_reward(self, weights):\n",
    "        initial_money = self.initial_money\n",
    "        starting_money = initial_money\n",
    "        self.model.weights = weights\n",
    "        state = self.get_state(0)\n",
    "        inventory = []\n",
    "        quantity = 0\n",
    "        for t in range(0, len(self.trend) - 1, self.skip):\n",
    "            action = self.act(state)\n",
    "            next_state = self.get_state(t + 1)\n",
    "            \n",
    "            if action == 1 and starting_money >= self.trend[t]:\n",
    "                inventory.append(self.trend[t])\n",
    "                starting_money -= close[t]\n",
    "                \n",
    "            elif action == 2 and len(inventory):\n",
    "                bought_price = inventory.pop(0)\n",
    "                starting_money += self.trend[t]\n",
    "\n",
    "            state = next_state\n",
    "        return ((starting_money - initial_money) / initial_money) * 100\n",
    "\n",
    "    def fit(self, iterations, checkpoint):\n",
    "        self.es.train(iterations, print_every = checkpoint)\n",
    "\n",
    "    def buy(self):\n",
    "        initial_money = self.initial_money\n",
    "        state = self.get_state(0)\n",
    "        starting_money = initial_money\n",
    "        states_sell = []\n",
    "        states_buy = []\n",
    "        inventory = []\n",
    "        for t in range(0, len(self.trend) - 1, self.skip):\n",
    "            action = self.act(state)\n",
    "            next_state = self.get_state(t + 1)\n",
    "            \n",
    "            if action == 1 and initial_money >= self.trend[t]:\n",
    "                inventory.append(self.trend[t])\n",
    "                initial_money -= self.trend[t]\n",
    "                states_buy.append(t)\n",
    "                print('day %d: buy 1 unit at price %f, total balance %f'% (t, self.trend[t], initial_money))\n",
    "            \n",
    "            elif action == 2 and len(inventory):\n",
    "                bought_price = inventory.pop(0)\n",
    "                initial_money += self.trend[t]\n",
    "                states_sell.append(t)\n",
    "                try:\n",
    "                    invest = ((close[t] - bought_price) / bought_price) * 100\n",
    "                except:\n",
    "                    invest = 0\n",
    "                print(\n",
    "                    'day %d, sell 1 unit at price %f, investment %f %%, total balance %f,'\n",
    "                    % (t, close[t], invest, initial_money)\n",
    "                )\n",
    "            state = next_state\n",
    "\n",
    "        invest = ((initial_money - starting_money) / starting_money) * 100\n",
    "        total_gains = initial_money - starting_money\n",
    "        return states_buy, states_sell, total_gains, invest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90cdf0d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ticker_name = '^GSPC'\n",
    "# start = '2021-01-04'\n",
    "# end = '2022-01-04'\n",
    "\n",
    "# Obtain stock data from Yahoo Finance\n",
    "df = yf.download(ticker_name, start=start, end=end).reset_index()\n",
    "\n",
    "close = df.Close.values.tolist()\n",
    "window_size = 30\n",
    "skip = 1\n",
    "initial_money = 10000\n",
    "\n",
    "model = Model(input_size = window_size, layer_size = 500, output_size = 3)\n",
    "agent = Agent(model = model, \n",
    "              window_size = window_size,\n",
    "              trend = close,\n",
    "              skip = skip,\n",
    "              initial_money = initial_money)\n",
    "agent.fit(iterations = 500, checkpoint = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "736fc728",
   "metadata": {},
   "outputs": [],
   "source": [
    "states_buy, states_sell, total_gains, invest = agent.buy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab77b2ab",
   "metadata": {},
   "source": [
    "# Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c53d1d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check performance\n",
    "\n",
    "print(f'\\n\\nInitial Capital: ${initial_money}')\n",
    "print(f'Final Balance: ${initial_money + total_gains:.2f}')\n",
    "print(f'Percentage Gain: {invest:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "975f59e4",
   "metadata": {},
   "source": [
    "# Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "535eae14",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (15,5))\n",
    "plt.plot(close, color='r', lw=2.)\n",
    "plt.plot(close, '^', markersize=10, color='m', label = 'buying signal', markevery = states_buy)\n",
    "plt.plot(close, 'v', markersize=10, color='k', label = 'selling signal', markevery = states_sell)\n",
    "plt.title(f'{ticker_name}\\nTotal Gains: ${total_gains:.2f}\\nPercentage Gain: {invest:.2f}%')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c234efd4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
